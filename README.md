# cs157a-tokenizer

Put the tokenizer3.py and the data folder in the same location or else it will not grab the data files properly.
The tokenizer3.py is the file that will be used to create the database and parse through the document - as well as TFiDF.



## Getting Started

First, you will need Python installed onto your computer. 
Go install Python 3 here: https://www.python.org/downloads/
Then, you will need to download the repository to your local development. 


### Installing

https://pythonprogramming.net/stemming-nltk-tutorial/
https://openpyxl.readthedocs.io/en/stable/

You will need to install the python libraries in your command line. You can read more about installing in the following links:

```
$ pip install ntlk
$ pip install openpyxl
```

When you're done, you can go to the folder directory that contains this repository and type the command below to run the Tokenizer:
```
$ py TokenizerClass.py
```


## Built With

* [Python](https://www.python.org/downloads/) - The language used
* [Nltk](https://www.nltk.org/install.html) - Natural Language Toolkit
* [Openpyxl](https://openpyxl.readthedocs.io/en/stable/) - Python Excel Spreadsheet


## Authors

* **Alexander Kamensky** 
* **Vivian Hoang** - *Initial work* - [SairenDelight](https://github.com/SairenDelight)
* **Tyler Veeman**
* **Sean Chan**
* **Justin Singh**

See also the list of [contributors](https://github.com/your/project/contributors) who participated in this project.

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details




